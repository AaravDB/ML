{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbj3q7asrkGoruRWezjrhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AaravDB/ML/blob/testing/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Lz7iMtE8cJ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function splits the dataset into training and test samples and seperates the features from the single column output."
      ],
      "metadata": {
        "id": "a_jBqmJazYrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD8cy9TiZ2lg"
      },
      "outputs": [],
      "source": [
        "def dataset_splitter(filename,column_name):\n",
        "  dat=pd.read_csv(filename)\n",
        "\n",
        "  y=np.array(dat[column_name])\n",
        "  ma=np.max(y)\n",
        "  X=np.array(dat.drop(column_name,axis=1))\n",
        "  X=X/ma\n",
        "  y=y/ma\n",
        "  X,X_te,y,y_te=train_test_split(X,y,train_size=0.8,random_state=42)\n",
        "  return X,X_te,y,y_te,ma"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function assigns the weights randomly,with values between 0 to 1."
      ],
      "metadata": {
        "id": "WsVNEv53za66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weights assignment,based on dimensions of dataset\n",
        "def weight_assigner(X_train):\n",
        "  a,b=X_train.shape\n",
        "  w=np.zeros(b+1)\n",
        "  return w"
      ],
      "metadata": {
        "id": "jQhVSJeEiuUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to iteratively learn better weights for predicting values on this dataset.\n",
        "It uses the negative gradient of the error to update the weights,and is pretty much independent of the dataset.\n",
        "It depends on parameters -learning rate and number of iterations-which decide whether the model is underfit,overfit or fits well to the datset."
      ],
      "metadata": {
        "id": "NI7e6L5Dxmno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(train_feat,train_outputs,iterations,l_r,wght):\n",
        "  m,n=train_feat.shape\n",
        "  cpy=wght\n",
        "  for i in range(iterations):\n",
        "    gradient=0\n",
        "    for j in range(m):\n",
        "      feat_vect=train_feat[j]\n",
        "      diff=np.dot(cpy,feat_vect)-train_outputs[j]\n",
        "      gradient+=diff*feat_vect\n",
        "    cpy=cpy-l_r*gradient\n",
        "  return cpy"
      ],
      "metadata": {
        "id": "csmwJTmRzEgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to find the mse for the predictions,a measure of accuracy in case of regression."
      ],
      "metadata": {
        "id": "FSdp1w7X3U68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(true,predicted):\n",
        "  return np.sum(np.square(np.subtract(true,predicted)))/len(true)"
      ],
      "metadata": {
        "id": "CLQytUJ3wH6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to make the predictions on the test dataset"
      ],
      "metadata": {
        "id": "P79y9xxfzl8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(wght,feature_vect_te):\n",
        "  predict=np.dot(feature_vect_te,wght)\n",
        "  return predict"
      ],
      "metadata": {
        "id": "LMPyASF4w7PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function finds the percentage error for regression"
      ],
      "metadata": {
        "id": "yeWKEWsdVVjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function does simple linear regression on a one dimensional dataset."
      ],
      "metadata": {
        "id": "09Ecuf8lJ9pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simplelinreg(filename,column_name,iter,l_r):\n",
        "  #learning\n",
        "  X,X_te,y,y_te,ma=dataset_splitter(filename,column_name)\n",
        "  weights=weight_assigner(X)\n",
        "  X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "  weights=gradient_descent(X,y,iter,l_r,weights)\n",
        "  return weights,X,X_te,y,y_te,ma\n",
        "wg,X,X_te,y,y_te,ma=simplelinreg('Linearreg.csv','Y',1000,0.001)"
      ],
      "metadata": {
        "id": "4-mvrIaZjYqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuiRzSsWHfrg",
        "outputId": "366cc4f9-c1bf-46eb-ca4a-619da84b166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.03261913 0.6331428 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to get back original relation we multiply the constant term by what we divided by"
      ],
      "metadata": {
        "id": "BNmsWz8RW9Af"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osRWSuLLW7_I",
        "outputId": "c52be1d1-f84f-4b26-f00a-3390bed0f15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.585440426872492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "19x86MvrHED2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_te[0])\n",
        "predictions=prediction(wg,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neE8bhbjOhLb",
        "outputId": "ab52daa3-a038-49b9-c1db-dfc5b328838b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0104568]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rxIPo3KiYgl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that linear regression will only work well on datasets where there is a linear relationship between the features and the output vectors.\n",
        "\n",
        "Thus it will fail on being applied to a dataset meant for classification."
      ],
      "metadata": {
        "id": "SGejLGrYy1pX"
      }
    }
  ]
}